{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pomber/covid19\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/corona19_world_data.csv does not exist: '../data/corona19_world_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-60b41f93eb8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/corona19_world_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datetime64[ns]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtoday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtomorrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../data/corona19_world_data.csv does not exist: '../data/corona19_world_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/corona19_world_data.csv', sep=',')\n",
    "df['date'] = df['date'].astype('datetime64[ns]')\n",
    "\n",
    "today = str(df.date.max().date())\n",
    "tomorrow = str(df.date.max().date() + datetime.timedelta(days=1))\n",
    "dayAfterTomorrow = str(df.date.max().date() + datetime.timedelta(days=2))\n",
    "yesterday = str(df.date.max().date() - datetime.timedelta(days=1))\n",
    "\n",
    "df[df['country']=='Brazil'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['country'].unique()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "### Predicting cases and death for a selected country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### selecting a country for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inform the countries for predictions\n",
    "predictedCountries = ['Brazil','Italy', 'United Kingdom', 'Spain', 'US', 'Belgium', 'France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = pd.DataFrame(columns=['country','ds', 'case_day', 'death_day', 'cases', 'deaths'])\n",
    "daysToPredict = 10\n",
    "\n",
    "for country in predictedCountries:\n",
    "    # preparing dataset for predictions\n",
    "    df_country = df.loc[df['country'] == country][['date','country','case_day','death_day']]\n",
    "    df_country.rename(columns={'date': 'ds'}, inplace= True)\n",
    "    df_cases = df_country.loc[:,['ds','case_day']]\n",
    "    df_cases.rename(columns={'case_day':'y'}, inplace =True)\n",
    "\n",
    "    df_deaths = df_country.loc[:,['ds','death_day']]\n",
    "    df_deaths.rename(columns={'death_day':'y'}, inplace =True)\n",
    "    \n",
    "    # fiting the model and making prediction\n",
    "    m_cases = Prophet(yearly_seasonality=False, daily_seasonality=False, interval_width=0.95, growth='linear')\n",
    "    m_cases.fit(df_cases)\n",
    "    m_deaths = Prophet(yearly_seasonality=False, daily_seasonality=False, interval_width=0.95, growth='linear')\n",
    "    m_deaths.fit(df_deaths)\n",
    "    \n",
    "    future_cases = m_cases.make_future_dataframe(periods=daysToPredict, freq='D', include_history=False)\n",
    "    future_deaths = m_deaths.make_future_dataframe(periods=daysToPredict, freq='D', include_history=False)\n",
    "    \n",
    "    forecast_cases = m_cases.predict(future_cases)\n",
    "    forecast_deaths = m_deaths.predict(future_deaths)\n",
    "    if country == 'Brazil':\n",
    "        fig = m_cases.plot_components(forecast_cases)\n",
    "        fig.savefig('../predictions/brazil_prophet_cases.png')\n",
    "        fig = m_deaths.plot_components(forecast_deaths)\n",
    "        fig.savefig('../predictions/brazil_prophet_deaths.png')\n",
    "        \n",
    "    p = forecast_cases.loc[:,['ds','yhat']]\n",
    "    p.rename(columns={'yhat': 'y'}, inplace= True)\n",
    "    t = df_cases.append(p[['ds','y']], ignore_index=True)\n",
    "    \n",
    "    p = forecast_deaths.loc[:,['ds','yhat']]\n",
    "    p.rename(columns={'yhat': 'y'}, inplace= True)\n",
    "    s = df_deaths.append(p[['ds','y']], ignore_index=True)\n",
    "\n",
    "    t['ds'] = t['ds'].astype('datetime64[ns]')\n",
    "    t.rename(columns={'y': 'case_day'}, inplace= True)\n",
    "    t['case_day'] = t['case_day'].astype('int32')\n",
    "    t['cases'] = t['case_day'].cumsum().astype('int32')\n",
    "    t['death_day'] = s['y'].astype('int32')\n",
    "    t['deaths'] = t['death_day'].cumsum().astype('int32')\n",
    "    t['country'] = country\n",
    "    t['predicted?'] = t['ds'] > today # para separar o que é previsão (True) do que é dado real (False)\n",
    "    df_prediction = df_prediction.append(t)\n",
    "    \n",
    "df_prediction.to_csv('../predictions/worldPredicion_' + today + '.csv', index = False)\n",
    "df_prediction.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.loc[df_prediction['ds']==tomorrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.loc[df_prediction['ds']==dayAfterTomorrow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_br = df_prediction.loc[df_prediction['country']=='Brazil']\n",
    "df_br.reset_index(0, inplace=True)\n",
    "\n",
    "x = df_br.index\n",
    "corte = df_br.loc[df_br.ds == str(today)].index[0]+1\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(10,10))\n",
    "fig.suptitle('Predicted on ' + today + ' day('+ str(corte) +') ' + ' for the next ' + str(daysToPredict) + ' days')\n",
    "fig.subplots_adjust(hspace = 0.5)\n",
    "ax1.set_title('cumulative')\n",
    "ax1.plot(x, df_br['cases'], label = 'cases')#, linewidths = 0.01)\n",
    "ax1.plot(x, df_br['deaths'], label = 'deaths')\n",
    "ax1.grid()\n",
    "ax1.axvline(x=corte, ymin=0, ymax=0.9, color = 'red', label = 'prediction')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_title('# daily (absolute numbers)')\n",
    "ax2.plot(x, df_br['case_day'], label = 'cases')\n",
    "ax2.plot(x, df_br['death_day'], label = 'deaths')\n",
    "ax2.grid()\n",
    "ax2.axvline(x=corte, ymin=0, ymax=0.9, color = 'red', label = 'prediction')\n",
    "ax2.legend()\n",
    "\n",
    "avg7_cases_million = df_br['case_day'].rolling(window=7).mean().replace([np.inf, -np.inf], 0).replace([np.nan], 0).astype('int')\n",
    "avg7_death_million = df_br['death_day'].rolling(window=7).mean().replace([np.inf, -np.inf], 0).replace([np.nan], 0).astype('int')\n",
    "\n",
    "ax3.set_title('# moving average (last 7 days)')\n",
    "ax3.plot(x, avg7_cases_million, label = 'cases')\n",
    "ax3.plot(x, avg7_death_million, label = 'deaths')\n",
    "ax3.grid()\n",
    "ax3.axvline(x=corte, ymin=0, ymax=0.9, color = 'red', label = 'prediction')\n",
    "ax3.legend()\n",
    "\n",
    "plt.savefig('../predictions/brazil_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../predictions/README.md', 'w')\n",
    "\n",
    "readme = '# **Predictions**\\n'\n",
    "readme += \"For experience, I'm running simple predictions over the cases and deaths per day. As they are time-series, I'm using [Facebook Prophet](https://facebook.github.io/prophet/docs/quick_start.html) that is also designed for this kind of prediction in a very simpler way. \"\n",
    "readme += \"It works well for most of the time; sometimes there is a huge leap and it takes sometime more data to be understood.\\n\\n\"\n",
    "readme += 'These predictions were made with Covid19 pandemic data from **' + today + '**.\\n\\n'\n",
    "readme += \"As there are many countries to have their data predicted in a row, I selected a few of them plus Brazil to be predicted:\\n\"\n",
    "readme += str(predictedCountries) + '.\\n'\n",
    "readme += '***Tip**: you can set yourself at the *[prediction.ipynb](../prediction.ipynb)* notebook which countries you prefer to predict*\\n\\n\\n'\n",
    "\n",
    "readme += '## The prediction\\n'\n",
    "readme += \"As Facebook Prophet predicts time-series data and it is running the prediction over cases per day and deaths per day. After that, I compute theirs cumulatives.\\\n",
    "It is predicting for the next 10 days.\\n\"\n",
    "readme += 'By the end, a CSV file containing all the predicted data is generated.\\n\\n'\n",
    "\n",
    "readme += \"#### The Brazil's last 5 days and predicted next 10 days\\n\"\n",
    "readme += \"*predicted? = True* means the line is a prediction; *=False* means they are real numbers.\\n\"\n",
    "readme += df_prediction[df_prediction['country']=='Brazil'].tail(15).to_markdown()\n",
    "\n",
    "readme += \"\\n\\n #### The predicted Brazil's cumulative curves\\n\"\n",
    "readme += \"The prediction are over the daily data, so, here they were cumulated and plotted with the actual data:\\n\"\n",
    "readme += '![](brazil_predictions.png)'\n",
    "\n",
    "readme += \"\\n\\nFacebook's Prophet automatically generates charts about the behaviour of the analysed and predicted data. That has a good visual information. Here are for the Brazil's prediction:\\n\"\n",
    "readme += \"### Cases\\n\"\n",
    "readme += '![](brazil_prophet_cases.png)\\n\\n '\n",
    "readme += \"### Deaths\\n\"\n",
    "readme += '![](brazil_prophet_deaths.png)\\n'\n",
    "\n",
    "readme += \"#### Finally, the predictions for selected countries for:\\n\"\n",
    "readme += '**Tomorrow**\\n'\n",
    "readme += df_prediction.loc[df_prediction['ds']==tomorrow].to_markdown()\n",
    "readme += '\\n\\n **The day after tomorrow** \\n'\n",
    "readme += df_prediction.loc[df_prediction['ds']==dayAfterTomorrow].to_markdown()\n",
    "\n",
    "f.write(readme)\n",
    "f.close()\n",
    "print('Predictions done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fbprophet.diagnostics import cross_validation\n",
    "# df_cv = cross_validation(m_cases, period='1 days', horizon = '10 days')\n",
    "# df_cv.head()\n",
    "\n",
    "# # Python\n",
    "# from fbprophet.diagnostics import performance_metrics\n",
    "# df_p = performance_metrics(df_cv)\n",
    "# df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fbprophet.diagnostics import performance_metrics\n",
    "# df_p = performance_metrics(df_cv)\n",
    "# df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
